{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "R0peUk-0nUOP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iG7LgkZInpsz"
   },
   "outputs": [],
   "source": [
    "Path = \"C:/Users/pc/Desktop/Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zPKI7FscnyKx",
    "outputId": "e4e2c694-2c6d-4cd9-9449-9a77196b759b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angry</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/1001_DFA_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Painful</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/1001_DFA_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stressful</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/1001_DFA_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prank</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/1001_DFA_HAP_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/1001_DFA_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emotion                                             Path\n",
       "0      Angry  C:/Users/pc/Desktop/Dataset/1001_DFA_ANG_XX.wav\n",
       "1    Painful  C:/Users/pc/Desktop/Dataset/1001_DFA_DIS_XX.wav\n",
       "2  Stressful  C:/Users/pc/Desktop/Dataset/1001_DFA_FEA_XX.wav\n",
       "3      Prank  C:/Users/pc/Desktop/Dataset/1001_DFA_HAP_XX.wav\n",
       "4    Neutral  C:/Users/pc/Desktop/Dataset/1001_DFA_NEU_XX.wav"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for wav in os.listdir(Path):\n",
    "  emotion = wav.partition(\".wav\")[0].split('_')\n",
    "  if emotion[0] == 'Abuse':\n",
    "      data.append(('Abusive', Path+'/'+wav))\n",
    "  if len(emotion) >= 3:\n",
    "    # if emotion[2] == 'DRU':\n",
    "    #   data.append(('Drunk', Path+'/'+wav))\n",
    "    if emotion[2] == 'DIS':\n",
    "      data.append(('Painful', Path+'/'+wav))\n",
    "    elif emotion[2] == 'FEA':\n",
    "      data.append(('Stressful', Path+'/'+wav))\n",
    "    elif emotion[2] == 'HAP':\n",
    "      data.append(('Prank', Path+'/'+wav))\n",
    "    elif emotion[2] == 'ANG':\n",
    "      data.append(('Angry', Path+'/'+wav))\n",
    "    elif emotion[2] == 'SAD':\n",
    "      data.append(('Sad', Path+'/'+wav))\n",
    "    elif emotion[2] == 'NEU':\n",
    "      data.append(('Neutral', Path+'/'+wav))\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df.rename(columns={0:'Emotion', 1:'Path'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kf3OSjf-ZuVN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angry</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/1001_DFA_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Painful</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/1001_DFA_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stressful</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/1001_DFA_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prank</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/1001_DFA_HAP_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/1001_DFA_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8561</th>\n",
       "      <td>Abusive</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/Abuse_995.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8562</th>\n",
       "      <td>Abusive</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/Abuse_996.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8563</th>\n",
       "      <td>Abusive</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/Abuse_997.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8564</th>\n",
       "      <td>Abusive</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/Abuse_998.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8565</th>\n",
       "      <td>Abusive</td>\n",
       "      <td>C:/Users/pc/Desktop/Dataset/Abuse_999.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8566 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                             Path\n",
       "0         Angry  C:/Users/pc/Desktop/Dataset/1001_DFA_ANG_XX.wav\n",
       "1       Painful  C:/Users/pc/Desktop/Dataset/1001_DFA_DIS_XX.wav\n",
       "2     Stressful  C:/Users/pc/Desktop/Dataset/1001_DFA_FEA_XX.wav\n",
       "3         Prank  C:/Users/pc/Desktop/Dataset/1001_DFA_HAP_XX.wav\n",
       "4       Neutral  C:/Users/pc/Desktop/Dataset/1001_DFA_NEU_XX.wav\n",
       "...         ...                                              ...\n",
       "8561    Abusive        C:/Users/pc/Desktop/Dataset/Abuse_995.wav\n",
       "8562    Abusive        C:/Users/pc/Desktop/Dataset/Abuse_996.wav\n",
       "8563    Abusive        C:/Users/pc/Desktop/Dataset/Abuse_997.wav\n",
       "8564    Abusive        C:/Users/pc/Desktop/Dataset/Abuse_998.wav\n",
       "8565    Abusive        C:/Users/pc/Desktop/Dataset/Abuse_999.wav\n",
       "\n",
       "[8566 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVO8GP7vY60b",
    "outputId": "114d941f-c829-4d6c-e508-c354552b493b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8566, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "xyDJ2J9tn3x1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "GpVcgbFpoOlZ",
    "outputId": "672e3aaf-a6f2-4fd9-cb46-bbcfc3dfcb79"
   },
   "outputs": [],
   "source": [
    "plt.title(\"Count of emotions:\")\n",
    "sns.countplot(x=df[\"Emotion\"])\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "n6RkjYJNoSR9"
   },
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr, e):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title(f'Waveplot for audio with {e} emotion', size=15)\n",
    "    librosa.display.waveplot(data, sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def create_spectrogram(data, sr, e):\n",
    "    # stft function converts the data into short term fourier transform\n",
    "    X = librosa.stft(data)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n",
    "    librosa.display.specshow(Xdb, sr=44100, x_axis='time', y_axis='hz')\n",
    "    #librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "j-BVa3wEo8Gh"
   },
   "outputs": [],
   "source": [
    "def noise(data, random=False, rate=0.035, threshold=0.075):\n",
    "    \"\"\"Add some noise to sound sample. Use random if you want to add random noise with some threshold.\n",
    "    Or use rate Random=False and rate for always adding fixed noise.\"\"\"\n",
    "    if random:\n",
    "        rate = np.random.random() * threshold\n",
    "    noise_amp = rate*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    \"\"\"Stretching data with some rate.\"\"\"\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data, rate=1000):\n",
    "    \"\"\"Shifting data with some rate\"\"\"\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*rate)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7, random=False):\n",
    "    \"\"\"\"Add some pitch to sound sample. Use random if you want to add random pitch with some threshold.\n",
    "    Or use pitch_factor Random=False and rate for always adding fixed pitch.\"\"\"\n",
    "    if random:\n",
    "        pitch_factor=np.random.random() * pitch_factor\n",
    "    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "szgrcm3PpRW7"
   },
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "hop_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vJK1Vj3BpVgy"
   },
   "outputs": [],
   "source": [
    "def zcr(data, frame_length=2048, hop_length=512):\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "\n",
    "def rmse(data, frame_length=2048, hop_length=512):\n",
    "    rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "\n",
    "def mfcc(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "    mfcc_feature = librosa.feature.mfcc(y=data, sr=sr)\n",
    "    return np.squeeze(mfcc_feature.T) if not flatten else np.ravel(mfcc_feature.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msD3tsYKpkge",
    "outputId": "ea2c819d-5ce9-48b3-d821-c7e2bfd93c19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30915"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = np.array(df[\"Path\"])[10]\n",
    "data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fdQXIhsWpqex"
   },
   "outputs": [],
   "source": [
    "def extract_features(data, sr, frame_length=2048, hop_length=512):\n",
    "    result = np.array([])\n",
    "    result = np.hstack((result,\n",
    "                        zcr(data, frame_length, hop_length),\n",
    "                        rmse(data, frame_length, hop_length),\n",
    "                        mfcc(data, sr, frame_length, hop_length)\n",
    "                                    ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Uda80IEOpuos"
   },
   "outputs": [],
   "source": [
    "def get_features(path, duration=2.5, offset=0.6):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=duration, offset=offset)\n",
    "\n",
    "     # without augmentation\n",
    "    res1 = extract_features(data, sample_rate)\n",
    "    result = np.array(res1)\n",
    "\n",
    "    # data with noise\n",
    "    noise_data = noise(data, random=True)\n",
    "    res2 = extract_features(noise_data, sample_rate)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "\n",
    "    # data with pitching\n",
    "    pitched_data = pitch(data, sample_rate, random=True)\n",
    "    res3 = extract_features(pitched_data, sample_rate)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "\n",
    "    # data with pitching and white_noise\n",
    "    new_data = pitch(data, sample_rate, random=True)\n",
    "    data_noise_pitch = noise(new_data, random=True)\n",
    "    res3 = extract_features(data_noise_pitch, sample_rate)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "opGGeDBrpyrp",
    "outputId": "950b9d3d-a3a3-454f-e425-7c831e7a8df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature processing...\n",
      "0 samples has been processed...\n",
      "100 samples has been processed...\n",
      "200 samples has been processed...\n",
      "300 samples has been processed...\n",
      "400 samples has been processed...\n",
      "500 samples has been processed...\n",
      "600 samples has been processed...\n",
      "700 samples has been processed...\n",
      "800 samples has been processed...\n",
      "900 samples has been processed...\n",
      "1000 samples has been processed...\n",
      "1100 samples has been processed...\n",
      "1200 samples has been processed...\n",
      "1300 samples has been processed...\n",
      "1400 samples has been processed...\n",
      "1500 samples has been processed...\n",
      "1600 samples has been processed...\n",
      "1700 samples has been processed...\n",
      "1800 samples has been processed...\n",
      "1900 samples has been processed...\n",
      "2000 samples has been processed...\n",
      "2100 samples has been processed...\n",
      "2200 samples has been processed...\n",
      "2300 samples has been processed...\n",
      "2400 samples has been processed...\n",
      "2500 samples has been processed...\n",
      "2600 samples has been processed...\n",
      "2700 samples has been processed...\n",
      "2800 samples has been processed...\n",
      "2900 samples has been processed...\n",
      "3000 samples has been processed...\n",
      "3100 samples has been processed...\n",
      "3200 samples has been processed...\n",
      "3300 samples has been processed...\n",
      "3400 samples has been processed...\n",
      "3500 samples has been processed...\n",
      "3600 samples has been processed...\n",
      "3700 samples has been processed...\n",
      "3800 samples has been processed...\n",
      "3900 samples has been processed...\n",
      "4000 samples has been processed...\n",
      "4100 samples has been processed...\n",
      "4200 samples has been processed...\n",
      "4300 samples has been processed...\n",
      "4400 samples has been processed...\n",
      "4500 samples has been processed...\n",
      "4600 samples has been processed...\n",
      "4700 samples has been processed...\n",
      "4800 samples has been processed...\n",
      "4900 samples has been processed...\n",
      "5000 samples has been processed...\n",
      "5100 samples has been processed...\n",
      "5200 samples has been processed...\n",
      "5300 samples has been processed...\n",
      "5400 samples has been processed...\n",
      "5500 samples has been processed...\n",
      "5600 samples has been processed...\n",
      "5700 samples has been processed...\n",
      "5800 samples has been processed...\n",
      "5900 samples has been processed...\n",
      "6000 samples has been processed...\n",
      "6100 samples has been processed...\n",
      "6200 samples has been processed...\n",
      "6300 samples has been processed...\n",
      "6400 samples has been processed...\n",
      "6500 samples has been processed...\n",
      "6600 samples has been processed...\n",
      "6700 samples has been processed...\n",
      "6800 samples has been processed...\n",
      "6900 samples has been processed...\n",
      "7000 samples has been processed...\n",
      "7100 samples has been processed...\n",
      "7200 samples has been processed...\n",
      "7300 samples has been processed...\n",
      "7400 samples has been processed...\n",
      "7500 samples has been processed...\n",
      "7600 samples has been processed...\n",
      "7700 samples has been processed...\n",
      "7800 samples has been processed...\n",
      "7900 samples has been processed...\n",
      "8000 samples has been processed...\n",
      "8100 samples has been processed...\n",
      "8200 samples has been processed...\n",
      "8300 samples has been processed...\n",
      "8400 samples has been processed...\n",
      "8500 samples has been processed...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "print(\"Feature processing...\")\n",
    "for path, emotion, ind in zip(df.Path, df.Emotion, range(df.Path.shape[0])):\n",
    "    features = get_features(path)\n",
    "    if ind % 100 == 0:\n",
    "        print(f\"{ind} samples has been processed...\")\n",
    "    for ele in features:\n",
    "        X.append(ele)\n",
    "        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n",
    "        Y.append(emotion)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "689ZixUsp1_L"
   },
   "outputs": [],
   "source": [
    "features_path = \"./features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "34aYXYMtqJEI",
    "outputId": "21840ff4-c0d7-405b-b534-90260291e0c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2367</th>\n",
       "      <th>2368</th>\n",
       "      <th>2369</th>\n",
       "      <th>2370</th>\n",
       "      <th>2371</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.148926</td>\n",
       "      <td>0.142090</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.070801</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>0.164551</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.100586</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.121582</td>\n",
       "      <td>0.135254</td>\n",
       "      <td>0.127930</td>\n",
       "      <td>0.114258</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060059</td>\n",
       "      <td>0.114746</td>\n",
       "      <td>0.176758</td>\n",
       "      <td>0.190430</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>0.145020</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.090332</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.062988</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>0.146484</td>\n",
       "      <td>0.125977</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Painful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.034180  0.069336  0.115723  0.148926  0.142090  0.130859  0.101562   \n",
       "1  0.041992  0.083984  0.136230  0.164551  0.154785  0.136719  0.100586   \n",
       "2  0.038086  0.074219  0.121582  0.135254  0.127930  0.114258  0.083496   \n",
       "3  0.060059  0.114746  0.176758  0.190430  0.177734  0.145020  0.101562   \n",
       "4  0.041504  0.059082  0.070312  0.062988  0.080566  0.128906  0.145508   \n",
       "\n",
       "          7         8         9  ...  2367  2368  2369  2370  2371  2372  \\\n",
       "0  0.070801  0.069336  0.074219  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1  0.071777  0.074219  0.080078  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2  0.073242  0.066406  0.069824  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3  0.087891  0.083496  0.090332  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "4  0.146484  0.125977  0.072266  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   2373  2374  2375   labels  \n",
       "0   NaN   NaN   NaN    Angry  \n",
       "1   NaN   NaN   NaN    Angry  \n",
       "2   NaN   NaN   NaN    Angry  \n",
       "3   NaN   NaN   NaN    Angry  \n",
       "4   NaN   NaN   NaN  Painful  \n",
       "\n",
       "[5 rows x 2377 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_df = pd.DataFrame(X)\n",
    "extracted_df[\"labels\"] = Y\n",
    "extracted_df.to_csv(features_path, index=False)\n",
    "extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5XLfM9SgqKsi",
    "outputId": "fef5f643-a8b1-4e08-dae6-37a1ca019c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34264, 2377)\n"
     ]
    }
   ],
   "source": [
    "extracted_df = pd.read_csv(features_path)\n",
    "print(extracted_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP35PBLqqMhF",
    "outputId": "80312b78-3e66-4776-c900-87998b031a1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         False\n",
      "1         False\n",
      "2         False\n",
      "3         False\n",
      "4         False\n",
      "          ...  \n",
      "2372      False\n",
      "2373      False\n",
      "2374      False\n",
      "2375      False\n",
      "labels    False\n",
      "Length: 2377, dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34264, 2377)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NaN with 0\n",
    "extracted_df = extracted_df.fillna(0)\n",
    "print(extracted_df.isna().any())\n",
    "extracted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "kPNXRsfUqPed",
    "outputId": "e59bf645-713b-4326-a077-47cb90b2577a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2367</th>\n",
       "      <th>2368</th>\n",
       "      <th>2369</th>\n",
       "      <th>2370</th>\n",
       "      <th>2371</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.148926</td>\n",
       "      <td>0.142090</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.070801</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>0.164551</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.100586</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.121582</td>\n",
       "      <td>0.135254</td>\n",
       "      <td>0.127930</td>\n",
       "      <td>0.114258</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060059</td>\n",
       "      <td>0.114746</td>\n",
       "      <td>0.176758</td>\n",
       "      <td>0.190430</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>0.145020</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.090332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.062988</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>0.146484</td>\n",
       "      <td>0.125977</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Painful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.034180  0.069336  0.115723  0.148926  0.142090  0.130859  0.101562   \n",
       "1  0.041992  0.083984  0.136230  0.164551  0.154785  0.136719  0.100586   \n",
       "2  0.038086  0.074219  0.121582  0.135254  0.127930  0.114258  0.083496   \n",
       "3  0.060059  0.114746  0.176758  0.190430  0.177734  0.145020  0.101562   \n",
       "4  0.041504  0.059082  0.070312  0.062988  0.080566  0.128906  0.145508   \n",
       "\n",
       "          7         8         9  ...  2367  2368  2369  2370  2371  2372  \\\n",
       "0  0.070801  0.069336  0.074219  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1  0.071777  0.074219  0.080078  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2  0.073242  0.066406  0.069824  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3  0.087891  0.083496  0.090332  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4  0.146484  0.125977  0.072266  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   2373  2374  2375   labels  \n",
       "0   0.0   0.0   0.0    Angry  \n",
       "1   0.0   0.0   0.0    Angry  \n",
       "2   0.0   0.0   0.0    Angry  \n",
       "3   0.0   0.0   0.0    Angry  \n",
       "4   0.0   0.0   0.0  Painful  \n",
       "\n",
       "[5 rows x 2377 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NDor49kPqRZ3"
   },
   "outputs": [],
   "source": [
    "X = extracted_df.drop(labels=\"labels\", axis=1)\n",
    "Y = extracted_df[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2DsCVxWqVEs",
    "outputId": "cff5fb38-6282-469e-b51b-c7cd21aabe88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abusive' 'Angry' 'Neutral' 'Painful' 'Prank' 'Sad' 'Stressful']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "Y = np_utils.to_categorical(lb.fit_transform(Y))\n",
    "print(lb.classes_)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27412, 2376) (27412, 7) (3426, 2376) (3426, 7) (3426, 2376) (3426, 7)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "newX = scaler.fit_transform(X)\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(newX):\n",
    "    X_train, X_val_test = newX[train_index], newX[test_index]\n",
    "    y_train, y_val_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    val_size = len(X_val_test) // 2\n",
    "    X_val = X_val_test[:val_size]\n",
    "    y_val = y_val_test[:val_size]\n",
    "    X_test = X_val_test[val_size:]\n",
    "    y_test = y_val_test[val_size:]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('X_val.npy', X_val)\n",
    "np.save('y_val.npy', y_val)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "7mJA9B2Iqigb"
   },
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                            patience=2,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "t4ZdbvH3qkRo"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "RSDzkDYOqmPp"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(64, kernel_size=5, strides=1,\n",
    "                        padding=\"same\", activation=\"relu\",\n",
    "                        input_shape=(X_train.shape[1], 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool1D(pool_size=5, strides=2, padding=\"same\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Conv1D(128, kernel_size=5, strides=1,\n",
    "                        padding=\"valid\", activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool1D(pool_size=5, strides=2, padding=\"same\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Conv1D(256, kernel_size=3, strides=1, padding='valid', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=3, strides = 2, padding = 'same'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Conv1D(512, kernel_size=3, strides=1, padding='valid', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=3, strides = 2, padding = 'same'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(7, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\", f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uStCdMiyqueg",
    "outputId": "3a7e7cd2-b94f-407f-d1e3-21be76ab82bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_20 (Conv1D)          (None, 2376, 64)          384       \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 2376, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 1188, 64)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 1188, 64)          0         \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 1184, 128)         41088     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 1184, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (None, 592, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 592, 128)          0         \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 590, 256)          98560     \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 590, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 295, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 295, 256)          0         \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 293, 512)          393728    \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 293, 512)         2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 147, 512)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 147, 512)          0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 75264)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               38535680  \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,078,919\n",
      "Trainable params: 39,075,975\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "psKt-uhGqwhV"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5MfacaKqyeA",
    "outputId": "b5304b82-e9fa-4172-9047-a1d8623d52f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "429/429 [==============================] - 529s 1s/step - loss: 1.5930 - acc: 0.4209 - f1_m: 0.3688 - val_loss: 1.6708 - val_acc: 0.3900 - val_f1_m: 0.3009 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "429/429 [==============================] - 498s 1s/step - loss: 1.2541 - acc: 0.5024 - f1_m: 0.4249 - val_loss: 1.4140 - val_acc: 0.4475 - val_f1_m: 0.3787 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "429/429 [==============================] - 517s 1s/step - loss: 1.1762 - acc: 0.5343 - f1_m: 0.4581 - val_loss: 1.2578 - val_acc: 0.5012 - val_f1_m: 0.3994 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "429/429 [==============================] - 530s 1s/step - loss: 1.0931 - acc: 0.5686 - f1_m: 0.5053 - val_loss: 1.2250 - val_acc: 0.5312 - val_f1_m: 0.4564 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "429/429 [==============================] - 536s 1s/step - loss: 1.0156 - acc: 0.6048 - f1_m: 0.5563 - val_loss: 1.7317 - val_acc: 0.4308 - val_f1_m: 0.4010 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9647 - acc: 0.6275 - f1_m: 0.5863\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "429/429 [==============================] - 533s 1s/step - loss: 0.9647 - acc: 0.6275 - f1_m: 0.5863 - val_loss: 1.6656 - val_acc: 0.5333 - val_f1_m: 0.4977 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "429/429 [==============================] - 533s 1s/step - loss: 0.7832 - acc: 0.7055 - f1_m: 0.6771 - val_loss: 1.0051 - val_acc: 0.6708 - val_f1_m: 0.6419 - lr: 2.0000e-04\n",
      "Epoch 8/20\n",
      "429/429 [==============================] - 531s 1s/step - loss: 0.6416 - acc: 0.7624 - f1_m: 0.7483 - val_loss: 0.8026 - val_acc: 0.7212 - val_f1_m: 0.7044 - lr: 2.0000e-04\n",
      "Epoch 9/20\n",
      "429/429 [==============================] - 532s 1s/step - loss: 0.5397 - acc: 0.8049 - f1_m: 0.7948 - val_loss: 0.8082 - val_acc: 0.7563 - val_f1_m: 0.7457 - lr: 2.0000e-04\n",
      "Epoch 10/20\n",
      "429/429 [==============================] - 532s 1s/step - loss: 0.4470 - acc: 0.8442 - f1_m: 0.8347 - val_loss: 0.6591 - val_acc: 0.8106 - val_f1_m: 0.8063 - lr: 2.0000e-04\n",
      "Epoch 11/20\n",
      "429/429 [==============================] - 532s 1s/step - loss: 0.3684 - acc: 0.8722 - f1_m: 0.8680 - val_loss: 0.5203 - val_acc: 0.8278 - val_f1_m: 0.8258 - lr: 2.0000e-04\n",
      "Epoch 12/20\n",
      "429/429 [==============================] - 535s 1s/step - loss: 0.3086 - acc: 0.8964 - f1_m: 0.8939 - val_loss: 0.4602 - val_acc: 0.8570 - val_f1_m: 0.8569 - lr: 2.0000e-04\n",
      "Epoch 13/20\n",
      "429/429 [==============================] - 536s 1s/step - loss: 0.2505 - acc: 0.9182 - f1_m: 0.9151 - val_loss: 0.3972 - val_acc: 0.8850 - val_f1_m: 0.8844 - lr: 2.0000e-04\n",
      "Epoch 14/20\n",
      "429/429 [==============================] - 537s 1s/step - loss: 0.2100 - acc: 0.9332 - f1_m: 0.9303 - val_loss: 0.3936 - val_acc: 0.8730 - val_f1_m: 0.8733 - lr: 2.0000e-04\n",
      "Epoch 15/20\n",
      "429/429 [==============================] - 536s 1s/step - loss: 0.1868 - acc: 0.9404 - f1_m: 0.9392 - val_loss: 0.2786 - val_acc: 0.9124 - val_f1_m: 0.9123 - lr: 2.0000e-04\n",
      "Epoch 16/20\n",
      "429/429 [==============================] - 536s 1s/step - loss: 0.1679 - acc: 0.9451 - f1_m: 0.9448 - val_loss: 0.3079 - val_acc: 0.9127 - val_f1_m: 0.9124 - lr: 2.0000e-04\n",
      "Epoch 17/20\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.1286 - acc: 0.9589 - f1_m: 0.9587\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "429/429 [==============================] - 538s 1s/step - loss: 0.1286 - acc: 0.9589 - f1_m: 0.9587 - val_loss: 0.2948 - val_acc: 0.9174 - val_f1_m: 0.9186 - lr: 2.0000e-04\n",
      "Epoch 18/20\n",
      "429/429 [==============================] - 537s 1s/step - loss: 0.1015 - acc: 0.9700 - f1_m: 0.9698 - val_loss: 0.2584 - val_acc: 0.9314 - val_f1_m: 0.9325 - lr: 4.0000e-05\n",
      "Epoch 19/20\n",
      "429/429 [==============================] - 537s 1s/step - loss: 0.0905 - acc: 0.9732 - f1_m: 0.9728 - val_loss: 0.2464 - val_acc: 0.9343 - val_f1_m: 0.9340 - lr: 4.0000e-05\n",
      "Epoch 20/20\n",
      "429/429 [==============================] - 537s 1s/step - loss: 0.0852 - acc: 0.9754 - f1_m: 0.9752 - val_loss: 0.2369 - val_acc: 0.9396 - val_f1_m: 0.9402 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=batch_size, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vwjSrX032dRN",
    "outputId": "5073f5dd-8a48-48e3-8134-a42f69bc2083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 10s 88ms/step - loss: 0.1441 - acc: 0.9550 - f1_m: 0.9555\n",
      "Accuracy of our model on test data :  95.50496339797974 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
